# Runtime params
#===================================
train: True # train new or existing model for each channel
predict: True # generate new predicts or, if False, use predictions stored locally
# number of values to evaluate in each batch
batch_size: 64

# number of trailing batches to use in error calculation
window_size: 30

# determines window size used in EWMA smoothing (percentage of total values for channel)
smoothing_perc: 0.05

# number of values surrounding an error that are brought into the sequence (promotes grouping on nearby sequences
error_buffer: 3

# LSTM parameters
# ==================================
loss_metric: 'mse'
optimizer: 'adam'
activation: 'relu'
validation_split: 0.2
dropout: 0.2
lstm_batch_size: 64
weight_decay : 0.01
learning_rate : 0.05
# maximum number of epochs allowed (if early stopping criteria not met)
epochs: 20
layer_LSTM : 3
# network architecture [<neurons in hidden layer>, <neurons in hidden layer>]
# Size of input layer not listed - dependent on evr modules and types included (see 'evr_modules' and 'erv_types' above)
layers: [100,100]

# Number of consequetive training iterations to allow without decreasing the val_loss by at least min_delta 
patience: 10
min_delta: 0.0003

# num previous timesteps provided to model to predict future values
# Questo Ã¨ il numero delle telemetrie minime per poter fare un analisi. Ovvero prima di fare una predizioni servono almeno 250 telemetrie come storico. ( vv erros.py 474)
l_s: 300

# number of steps ahead to predict
n_predictions: 2

# Error thresholding parameters
# ==================================

# minimum percent decrease between max errors in anomalous sequences (used for pruning)
p: 0.50

dataset_path : "kuka_dataset"
config_path : "Models/telemanom/config.yaml"
run_id : None
